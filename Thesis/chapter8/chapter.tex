% !TEX root = ../thesis.tex
\chapter{Conclusions \& Future Work}
\label{chapter:conclusions_future_work}
\thispagestyle{empty}

The aim of this chapter is to briefly draw the conclusions of our research, summarizing what has been done during the thesis work and providing some ideas for further research in this area.

We first recapitulate our work in a \textit{conclusive summary}, providing the reader with a synopsis of what has been seen in the previous chapters, and we then suggest \textit{future work} to be potentially done starting from this research and some possible paths that might be worth to follow.


\section{Conclusive Summary}
As previously pointed out in Chapter~\ref{chapter:introduction}, the aim of this research is not to solve the huge and multifaceted problem of discrimination in data, but rather to take a look at the current state of the art, observing some tools in action and trying to highlight their strengths and weaknesses, and also providing a non-technical perspective to give a broader picture of the situation by investigating the problem in the sociological field to obtain additional information about the context in which data are embedded and to understand to what extent the problem is to be found in the instrumentation and technical choices and to what extent it is instead rooted in society.

To pursue our goal we therefore began by reviewing, starting from the general notions of fairness and data management, both socio-ethical and technical literature in order to dive deep into the topics and capture the several facets of the problem of discovering bias in data.

For what concerns the socio-ethical side, we classified three categories of bias, different in origin and in nature; we clarified what discrimination is, and how it is connected to human rights; and we distinguished between equality and equity, extending the concepts to the data perspective, and finally pointing at what both approaches aim to achieve: fairness.

On the technical side, we first introduced the basics of the data analysis discipline by providing explanations on relational databases, data science pipeline, and data mining techniques; we then explored some more specific concepts such as linear regression and functional dependencies, also providing detailed information on some evaluation metrics for them, and on some other useful statistical concepts; and we finally described, referring to the documentation at our disposal, the tools we decided to adopt for our analysis: the `Glassdoor Method', FAIR-DB, and Ranking Facts.

After this first literature review phase, we conducted parallel research in sociology and information technology, investigating the various possible causes of gender discrimination by examining writings and studies by experts in the field and retrieving information useful for a comparison with our case studies, and also conducting experiments to test the effectiveness of our tools and understand what design choices can lead to the introduction or the exacerbation of bias in the data.

Once chosen the datasets on which to work and the specific focus of our research -- gender gap -- we retrieved information on the problem in the society, overall at first, introducing The Global Gender Gap Index, and then focusing on the U.S., providing different point of views and reasons for the presence of gender discrimination in the workplace, such as statistical discrimination, impact of the institutional environment, and inequalities related to unequal bargaining power; and finally we showed some data and statistics from the U.S. Department of Labor, in order to make more concrete the reflections previously reported.

Meanwhile, through the use of Python and Jupyter Notebook, we did some experiments on our datasets, in order to verify the possible presence of bias in the data, potentially leading to gender discrimination and unfair outcomes: for both our case studies -- Chicago and San Francisco -- after having provided a more detailed description of the datasets, we performed some data preprocessing operations; and we used the tools previously described to analyze them. We tried to identify -- both during the preprocessing and the actual analysis -- the most critical choices we had to deal with (such as the part-time employees removal, the choice of the number of bins and the most suitable dependencies for the FAIR-DB analysis, or the grouping of similar job titles) pointing them as potential sources of bias; and we conducted other experiments on the same data but taking different paths, also trying to voluntarily introduce bias in the data, and ultimately evaluating the impact of different design decisions on our outcomes.


\section{Future Work}
In this final section we want to highlight some aspects which we think would deserve further study or development in future research.

First of all, having seen the different approaches of the adopted tools and the different perspectives they provide, it would be interesting to combine them all in a unique, more complete instrument, in order to give the user a single tool that provides multiple points of view, rather than several partial ones which the user themselves may not combine, maybe because not aware of the existence of each. Further efforts may be invested in trying to encompass even more facets of equity, or more definitions of fairness.

Even assuming such an instrument is developed, however, analyses of these kind should always be supported by sociological research, in order to get a broader perspective on the problem and capture facets which would not be captured otherwise (in our case, the representation issue).

The sociological research could also be further enriched by conducting an interview with workers and HR practitioners of the cities under study, in order to get more specific, recent, and precise information useful for interpreting the results.

For what concerns datasets, it would be appropriate to retrieve further information in support of the mere data, in order to get a more exhaustive overview, and since having more information usually leads to more accurate results. This also could be an incentive for developers, database administrators, and other professionals in the IT sector, to create effective documentation in support of data and technological tools. This documentation should, as far as possible, be detailed and at the same time easy to experience, so as to potentially enable professionals from other sectors (for example, sociologists) to get an idea of what is included in the data or how to use a tool in a conscious way. In this regard, we refer back to the considerations on context-awareness made in Chapter~\ref{chapter:outcomes_contributions}, emphasizing once again the importance of the context and the contribution of sociological investigation to the delineation of the context itself.
