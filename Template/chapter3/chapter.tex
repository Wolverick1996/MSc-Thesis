% !TEX root = ../thesis.tex
\chapter{Technical Preliminaries}
\label{chapter3}
\thispagestyle{empty}

The aim of this chapter is to provide to the reader preliminary notions about the tools adopted for this research and the related technical knowledge.

We will start by introducing \textit{relational databases}, the \textit{data science pipeline} and \textit{data mining techniques}, and then focusing on more specific concepts such as \textit{linear regression} and \textit{functional dependencies}. An explanation of some needed \textit{evaluation metrics} and \textit{statistical concepts} will follow, and finally a description of the tools will be provided.

As specified in Chapter~\ref{chapter2}, the complementarity of the preliminaries is one of the key points of this research, and will allow the reader to have two perspectives of a different nature on the same problem.


\section{Relational Databases}
\label{section:relational_databases}
When dealing with computer systems, one of the most basic notions, often inappropriately taken for granted, is the one of ``\textbf{data}'', definable as:
\begin{quote}\emph{Information, especially facts or numbers, collected to be examined and considered and used to help decision-making, or information in an electronic form that can be stored and used by a computer.} \cite{cambridge2013data}\end{quote}
Therefore, a large amount of data stored in a computer in some organized manner is called a \textbf{database}. To be more precise, a database is ``any collection of data, or information, that is specially organized for rapid search and retrieval by a computer'' \cite{britannica2020database}; while the software that supports the management of these data is called a \textbf{database management system (DBMS)}.

The history of databases is deeply interconnected with the history of informatics itself, because the problem of how to store and retrieve information appeared as one of the initial challenges of computer creators. However, in the past few decades the rapid and enormous evolution of computer systems and databases led to the adoption and the development of the so called ``data models''. A \textbf{data model} \cite{abiteboul1995foundations} is an abstract representation of an information system, which defines the data elements and the relationships between data elements. The aim of a data model is to give a clear and intuitive overview on how a system looks like, by providing a standardized description of its components, in such a way as to facilitate the understanding of the system itself and the possible integration with other systems.

Nowadays, the most widespread data model is the \textbf{relational model}, firstly proposed by Codd in \cite{codd1970relational}. The relational model represents a database as a collection of relations, depicted as tables of values. Each row of the table is a collection of related data values, referring to a real-world entity or relationship between entities. Therefore, we can simply define a \textbf{relational database} as a digital database based on the relational model of data.
To make it clearer, the following list provides the main terms used in this context, together with a concise explanation, while Figure~\ref{fig:relational_model} shows them in a trivial example.
\begin{itemize}
\item \textbf{Table}, or \textbf{relation}: modeling of a real-world entity or of a relationship between real-world entities.
\item \textbf{Row}, or \textbf{tuple}: single data record.
\item \textbf{Column}, or \textbf{attribute}: property, or feature, of a relation.
\item \textbf{Cardinality}: total number of tuples of a relation.
\item \textbf{Degree}: total number of attributes of a relation.
\item \textbf{Primary key}: attribute, or combination of attributes, that uniquely identifies a tuple among the others.
\item \textbf{Domain}, or \textbf{data type}: set of values that a specific attribute can assume (for example, integer numbers, or boolean values).
\item \textbf{Database schema}, or simply \textbf{schema}: blueprint of the database that outlines the way its structure organizes data into tables.
\item \textbf{Database instance}, or simply \textbf{instance}: set of tuples in which each tuple has the same number of attributes as one of the relations of the database schema. It specifies the actual content of the database.
\item \textbf{Integrity constraint}: property that is supposed to be satisfied by all instances of a database schema.
\end{itemize} 

\begin{figure}[t!]
\includegraphics[scale=.75]{figures/relational_model.pdf}
\centering
\caption{Relational model concepts in a trivial example. ``Employee'' is the name of the real-world entity of reference and therefore of the related table in the model.}
\label{fig:relational_model}
\end{figure}

Lastly, since this term will be often used in the subsequent sections and chapters, we define a \textbf{dataset} as a collection of data. More specifically, since our data are in a tabular format according to the relational model, a dataset simply corresponds to one or more database tables.

Further details on relational databases can be found in \cite{abiteboul1995foundations}.


\section{Data Science Pipeline}
\label{section:data_science_pipeline}
Because of the broadness of the concept, there is not a unique and precise definition of data management. In general, we can identify it as the process of acquiring, storing, organizing, and maintaining data created and collected by an organization. In \cite{gandomi2015beyond}, the author, referring to \cite{labrinidis2012challenges}, classifies \textit{data management}, together with \textit{analytics}, as one of the two sub-processes to extract insights from data, while the overarching process is referred as \textbf{data science pipeline}, or \textit{big data pipeline}. For the sake of clarity, since the term is the one used in \cite{gandomi2015beyond}, we define big data as:
\begin{quote}
\emph{Large volumes of high velocity, complex and variable data that require advanced techniques and technologies to enable the capture, storage, distribution, management, and analysis of the information.} \cite{mills2012demystifying}\end{quote}
However we preferred to adopt the name of ``data science pipeline'' instead of ``big data pipeline'', since we will not deal with big data, which are not a concept strictly inherent to this research.

\begin{figure}[t!]
\includegraphics[scale=.5]{figures/data_science_pipeline.pdf}
\centering
\caption{Data science pipeline. Image based on the one shown in \cite{gandomi2015beyond}.}
\label{fig:data_science_pipeline}
\end{figure}

Since fairness should be addressed in each phase of the data science pipeline, the subsequent list provides a concise explanation of the operations performed in each step, by following the classification proposed in \cite{jagadish2014big}, together with the main potential sources of bias.
\begin{itemize}
\item \textbf{Acquisition and recording}: data are recovered and captured. In this phase the introduction of bias could derive from some preliminary critical choices we have to deal with, concerning the availability of sources, the identification of who is represented by the data, the definition of what has been measured and of our duties to the people in the data (for example, we may owe them a certain degree of privacy).
\item \textbf{Extraction, cleaning and annotation}: real data are most of the time messy and dirty, therefore we need to extract the relevant information and clean them, in order to express them in a structured form suitable for analysis. Unfortunately, data cleaning itself is based on assumptions, and wrong assumptions may lead to bias (for example, we may assume missing values in the data as missing at random, while there could be other, maybe ethical, reasons behind).
\item \textbf{Integration, aggregation and representation}: data analysis often requires the collection of heterogeneous data from different sources, therefore we need to integrate them in order to guarantee syntactic and semantic coherence. Again, we have to rely on assumptions on the world, as for the case of data representation, in which a lot of choices are made in order to decide what to represent, potentially leading to bias (for example, in the context of sentiment analysis we may ascribe sentiment to labels, or we may decide to group age values instead of considering every single year).
\item \textbf{Modeling and analysis}: before the actual analysis, an abstract model of the data is generated, in order to capture the essential components of the system and their interactions. However, the process of abstraction of concrete data in a conceptual standard model necessarily leads to the loss of information (for example, the relational model provides an intuitive overview of the system, but it does not include any semantics).
\item \textbf{Interpretation}: a decision-maker, provided with the results of the analysis, has to interpret these results. This process usually requires to examine all the assumptions made and to retrace the analysis, and because of the complexity of the task and the problems that may arise from computer systems (bugs, errors), a human (and therefore impossibly perfectly fair) supervision is needed (for example, the failures of system components can go unnoticed and result in loss of data, or the data format may have changed without being notified, and therefore the system should be equipped with monitoring scripts and mechanisms to obtain user confirmation and correction).
\end{itemize}


\section{Data Mining Techniques}
\label{section:data_mining_techniques}
\begin{quote}
\emph{Data mining is a collection of techniques for efficient automated discovery of previously unknown, valid, novel, useful and understandable patterns in large databases.} \cite[p.~80]{tamilselvi2015efficient} \end{quote}
Data mining is a broad topic, and usually a variety of procedures are needed in order to gain knowledge from data. However, we can distinguish three main categories of techniques, in each of which the fairness problem should be addressed differently:
\begin{itemize}
\item \textbf{Preprocessing techniques}: procedures used to transform the raw data in a useful and efficient format. The aim is to improve the overall quality of the data and consequently the data mining results.
\item \textbf{Inprocessing techniques}: data are subjected to various methods using machine learning and artificial intelligence algorithms to generate a desirable output.
\item \textbf{Postprocessing techniques}: methods to evaluate the extracted knowledge, visualize it, or merely document it for the end user. The knowledge can also be interpreted and incorporated into an existing system.
\end{itemize}

For the purpose of this research, we will focus on preprocessing techniques, which constitute one of the most critical steps in the data mining process, since they deal with the preparation and transformation of the initial dataset; while the bias analysis we will perform making use of the tools adopted is part of data (in)processing. Data preprocessing methods are divided into four categories \cite{tamilselvi2015efficient}:
\begin{itemize}
\item \textbf{Data cleaning}: since real-world data are often incomplete, noisy, and inconsistent, some routines are needed in order to fill in missing values, smooth out the noise and correct the inconsistencies.
For what concerns \textit{missing values}, these procedures include the removal of the specific tuple, or the filling (manual or automatic) of the missing value by using, for example, a constant (e.g. ``unknown''), the mean (for numerical attributes) or simply what is perceived to be the most probable value.
Noise instead can be seen as a random error or variance in a measured variable, and some smoothing techniques for \textit{noisy data} are:
\begin{itemize}
\item \textbf{Binning}: a data value is smoothed by looking at its ``neighbourhood'', that is, the values around it.
\item \textbf{Regression}: data are fitted to a function, in order to be smoothed according to the function itself. A specific type of regression, useful for our analysis, is \textit{linear regression}, which will be furtherly explored in Section~\ref{section:linear_regression}.
\item \textbf{Clustering}: similar data are organized into groups of values, called ``clusters''. Values that fall outside the set of clusters may be considered as outliers.
\end{itemize}
\item \textbf{Data integration}: as mentioned in Section~\ref{section:data_science_pipeline}, data often come from different (possibly heterogeneous) sources, and therefore they need to be combined in order to obtain a coherent model and remove inconsistencies (such as redundancies between attributes, where some can be derived from others).
\item \textbf{Data transformation}: data are transformed or consolidated in appropriate forms suitable for the mining process. Some techniques used in this context are:
\begin{itemize}
\item \textbf{Normalization}: data values are scaled so as to fall within a specified range, such as (\(-\)1.0, 1.0 or 0.0, 1.0).
\item \textbf{Aggregation}: new attributes are constructed from the given set of attributes to help the mining process by summarizing or aggregating information (for example, daily sales data may be aggregated so as to compute annual total amounts).
\item \textbf{Generalization}: raw (or low-level) data are replaced by higher-level ones, by following a specific hierarchy (for example, the attribute ``city'' can be generalized to ``country'').
\item \textbf{Discretization}: raw values of numeric attributes are replaced by interval levels or conceptual levels (for example, age values between 15 and 18 could be labeled as ``adolescence'').
\end{itemize}
\item \textbf{Data reduction}: in order to make mining more effective and get better analytical results, several techniques can be applied to obtain a reduced representation of the dataset that is much smaller in volume, yet closely maintains the integrity of the original data. These methods include, among the others, \textit{attribute subset selection}, in which attributes considered as not particularly relevant for the analysis are removed, and \textit{numerosity reduction}, where data are replaced by smaller data representations, such as parametric models.
\end{itemize}


\section{Linear Regression}
\label{section:linear_regression}
In order to fully understand how one of the adopted tools works (the one we refer to as ``Glassdoor Method'', described later in Section~\ref{section:the_glassdoor_method}), it is appropriate to have a closer look at \textbf{linear regression} \cite{glasserman2001linear}. As mentioned in Section~\ref{section:data_mining_techniques}, linear regression is a preprocessing technique used to smooth out noise or to find patterns within a dataset, which attemps to model the relationship between two or more variables by fitting data to a linear equation (represented, in the two-variable case, by a straight line in a Cartesian plane). The results from linear regression help in predicting an unknown value depending on the relationship with the predicting variables. For example, the height and weight of an individual generally are related: usually taller people tend to weigh more. We could use regression analysis to help predict the weight of a person, given their height.

We can distinguish between \textbf{simple linear regression}, in which a single input variable is used to model a linear relationship with the target variable (as for the example of height and weight), and \textbf{multiple linear regression}, where more predicting variables are used.

For simple linear regression, the reference equation is: \[y = \beta_0 + \beta_1x + \epsilon\]
Variable \(x\) is called \textit{explanatory} or \textit{independent variable}, while \(y\) is referred to as \textit{dependent variable}; \(\beta_1\) is the \textit{slope} of the line, also known as regression coefficient, and \(\beta_0\) is the \textit{intercept} (the value of \(y\) when \(x = 0\)), while \(\epsilon\) is the \textit{error} in the estimation of the regression coefficient, also known as residuals, which account for the variability in \(y\) that cannot be explained by the linear relation between \(x\) and \(y\).

For multiple linear regression, the formula is generalized in order to incapsulate also the other independent variables (\(x_1, \ldots, x_n\)) and the related slope coefficients (\(\beta_1, \ldots, \beta_n\)): \[y = \beta_0 + \beta_1x_1 + \ldots + \beta_nx_n + \epsilon\]

\begin{figure}[t!]
\includegraphics[scale=.7]{figures/simple_linear_regression.pdf}
\centering
\caption{Simple linear regression graph.\newline
Source: \upshape\protect\url{https://www.reneshbedre.com/assets/posts/reg/mlr/residual.svg}.}
\label{fig:simple_linear_regression}
\end{figure}

Figure~\ref{fig:simple_linear_regression} shows a simple linear regression graph. It is important to point out that the \(x\) and \(y\) variables remain the same, since they represent data features that cannot be changed, while the values that we can control are the slope and the intercept. Indeed, there can be multiple straight lines depending upon the values of intercept and slope, and what the linear regression algorithm does is to fit multiple lines on the data points and return the line that results in the least error.

Another important parameter for regression analysis is \(R^2\), also known as \textit{coefficient of determination} (or \textit{coefficient of multiple determination} for multiple linear regression). It is a statistical measure of how close the data are to the fitted regression line, and therefore it indicates how much variation of the dependent variable is explained by the independent variable(s) in a regression model. \(R^2\) values range from 0 to 1 and are commonly stated as percentages from 0\% to 100\%, where 0\% refers to a model that explains none of the variability of the data around its mean, while 100\% refers to a model that explains all the variability of the data around its mean (in this case, all the actual data values would be on the regression line).

Formally, we can define \(R^2\) as: \[R^2 = 1 - \frac{\mathit{Unexplained Variation}}{\mathit{Total Variation}} = 1 - \frac{\sum_{i}(y_i - \hat{y}_i)}{\sum_{i}(y_i - \bar{y})}\] where \(y_i\) is one of the actual data values, \(\hat{y}_i\) is the corresponding predicted value, and \(\bar{y}\) is the mean of all the \(y_i\) values, for \(i = 1, \ldots, n\).

Generally speaking, at least for the purpose of this research, the higher the \(R^2\) value, the better the model fits the data.


\section{Functional Dependencies}
\label{section:functional_dependencies}
One of the tools adopted, FAIR-DB, uses specific classes of integrity contraints, known as dependencies, to detect unfair behaviors in datasets (further details on the tool will be provided in Section~\ref{section:fair-db}). A \textbf{dependency} is a constraint that applies to or defines the relationship between attributes, and it occurs in a database when information stored in a table uniquely determines other information stored in the same table. Basically, dependencies are constraints not necessarily imposed by the system designer but intrinsically satisfied by the data.

\textbf{Functional dependencies (FDs)} are a specific type of dependency, involving two (sets of) attributes of the same relation in which the first uniquely determines the second or, in other words, knowing the value of one attribute (or set of attributes) is enough to tell the value of the other one. The notation to indicate a functional dependency is: \[A \rightarrow B\] which can be read as ``\(B\) is functionally dependent upon \(A\)'', or ``\(A\) uniquely determines \(B\)'', whereas \(A\) and \(B\) are attributes (or eventually sets of attributes) of a table. \(A\) is called antecedent, or \textit{left-hand-side (LHS)}, and \(B\) consequent, or \textit{right-hand-side (RHS)}. An example of functional dependency could be the one of a table containing the information about the employees of a company, as in Figure~\ref{fig:relational_model}. Here the \(\mathit{ID}\) attribute uniquely identifies the \(\mathit{Name}\) one, because by knowing the employee's ID we can tell what the employee's name is. Therefore, \(\mathit{ID} \rightarrow \mathit{Name}\). More specifically, since also the employee's surname and gender are uniquely identified by the ID, we can write \(\mathit{ID} \rightarrow \mathit{Name}, \mathit{Surname}, \mathit{Gender}\). Another example is provided in Table~\ref{table:orange_plantation}, in which \(\mathit{Temperature}, \mathit{pH}, \mathit{Season} \rightarrow \mathit{Ideal}\).

\begin{table}
\begin{tabular}{|p{2.5cm}|p{2.5cm}|p{2.5cm}|p{2.5cm}|}
\hline
\multicolumn{4}{|c|}{Orange Plantation}\\
\hline
Temperature & pH & Season & Ideal\\
\hline
28 & 7 & Autumn & Y\\
20 & 7 & Autumn & N\\
28 & 7 & Winter & N\\
29 & 7.5 & Autumn & Y\\
27 & 6.5 & Winter & N\\
27 & 7.5 & Summer & N\\
20 & 6.5 & Spring & N\\
28 & 7 & Summer & N\\
27 & 6.5 & Autumn & Y\\
\hline
\end{tabular}
\centering
\caption{``Orange Plantation'' table. It shows whether or not ambient temperature (\textdegree C), soil pH and planting season represent ideal conditions for planting oranges.}
\label{table:orange_plantation}
\end{table}

Functional dependencies are a very well-known concept for data scientists, especially for those who work on relational models, and further details on them can be found in \cite{abiteboul1995foundations}.
However, the constraints imposed by functional dependencies are often too strict for real-world datasets (they must indeed hold for all the tuples of a table), so in the past few years generalizations of FDs have been proposed and started to be considered in their place. \textbf{Relaxed functional dependencies (RFDs)} can indeed be simply defined as functional dependencies where some constraints are deleted (relaxed). The authors of \cite{caruccio2015relaxed} distinguished 35 different categories of RFDs, but the ones relevant for our research are the following:
\begin{itemize}
\item \textbf{Approximate functional dependencies (AFDs)}:
\begin{quote}\emph{AFDs are FDs holding on almost every tuple.} \cite[p.~151]{caruccio2015relaxed}\end{quote}
In order to quantify how an AFD ``almost'' holds, several measures have been proposed, including the so called \textit{g3}, defined as ``the (normalized) minimum number of tuples that need to be removed from a relation instance in order for an FD to hold'' \cite[p.~151]{caruccio2015relaxed}, whereas ``relation instance'' is simply a synonym of ``relation''. The g3 measure is therefore an index whose value ranges between 0 and 1, indicating the percentage of tuples of a table to be removed in order for an FD to hold (0 = none, 1 = all). An example of AFD in Table~\ref{table:orange_plantation} is: \[\mathit{Temperature}, \mathit{pH} \rightarrow \mathit{Ideal}\] because almost all the values of \(\mathit{Temperature}\) and \(\mathit{pH}\) determine the \(\mathit{Ideal}\) value, but this is not true for: \[\mathit{Temperature} = \mlq 28 \mrq, \mathit{pH} = \mlq 7 \mrq \rightarrow \mathit{Ideal}\] since in most of the cases (two out of three) when \(\mathit{Temperature} = \mlq 28 \mrq\) and \(\mathit{pH} = \mlq 7 \mrq\) then \(\mathit{Ideal} = \mlq \mathrm{Y} \mrq\), but in one case \(\mathit{Ideal} = \mlq \mathrm{N} \mrq\).
\item \textbf{Conditional functional dependencies (CFDs)}:
\begin{quote}\emph{[CFDs] use conditions to specify the subset of tuples on which a dependency holds.} \cite[p.~152]{caruccio2015relaxed}\end{quote}
This type of dependencies allows to catch particular and concrete patterns in the dataset, in fact they make possible to analyze precise values of the tuples and be more specific. An example of CFD, related to Table~\ref{table:orange_plantation}, is the following: \[\mathit{Temperature} = \mlq 28 \mrq, \mathit{pH} = \mlq 7 \mrq, \mathit{Season} \rightarrow \mathit{Ideal}\] meaning that, for tuples in which \(\mathit{Temperature} = \mlq 28 \mrq\) and \(\mathit{pH} = \mlq 7 \mrq\), the \(\mathit{Season}\) parameter functionally determines the \(\mathit{Ideal}\) one. Another example could be: \[\mathit{Season} = \mlq \mathrm{Summer} \mrq \rightarrow \mathit{Ideal} = \mlq \mathrm{N} \mrq\] interpretable as: ``when the attribute \(\mathit{Season}\) has value \(\mathrm{Summer}\), the attribute value of \(\mathit{Ideal}\) is \(\mathrm{N}\)''.
\item \textbf{Approximate conditional functional dependencies (ACFDs)}: FDs obtained by combining the two kinds of relaxed dependencies discussed above. Unifying the two relaxation criteria makes it possible to detect specific and not exact rules, which can highlight anomalies or unexpected patterns in the database, allowing to recognize cases where a value of a certain attribute \textit{frequently determines} the value of another one. An example of ACFD in Table~\ref{table:orange_plantation} is: \[\mathit{Season} = \mlq \mathrm{Autumn} \mrq \rightarrow \mathit{Ideal} = \mlq \mathrm{Y} \mrq\] which can be read as: ``when attribute \(\mathit{Season}\) has value \(\mathrm{Autumn}\), the attribute value of \(\mathit{Ideal}\) is \(\mathrm{Y}\) if we delete a maximum number of tuples \(N\) from the dataset''. The rule indeed holds for almost all the tuples of the table, apart for the one in which \(\mathit{Temperature} = \mlq 20 \mrq\), \(\mathit{pH} = \mlq 7 \mrq\), \(\mathit{Season} = \mlq \mathrm{Autumn} \mrq\) and \(\mathit{Ideal} = \mlq \mathrm{N} \mrq\). It is worth to specify that, even though the notation is the same used for CFDs, the relaxation on the number of tuples is implicit in the classification of a rule as an ACFD.
\end{itemize}


\section{Evaluation Metrics}
\label{section:evaluation_metrics}
The aim of this section is to introduce some evaluation metrics for functional dependencies used by one of the adopted tools, FAIR-DB, described later in Section~\ref{section:fair-db}.

\begin{itemize}
\item \textbf{Support}: \[\mathrm{Support}(X \rightarrow Y) = \mathrm{supp}(X, Y) = \frac{\#(X, Y)}{\mathit{\#tuples}}\] where \(\#(X, Y)\) is the amount of times the (sets of) attributes \(X\) and \(Y\) appear together in the dataset and \(\#tuples\) is the total amount of tuples in the table. The support represents the percentage of records in the dataset that verify the dependency \(X \rightarrow Y\), and it is therefore an index whose value ranges between 0 and 1.
\item \textbf{Confidence}: \[\mathrm{Confidence}(X \rightarrow Y) = \mathrm{conf}(X, Y) = \frac{\mathrm{supp}(X, Y)}{\mathrm{supp}(X)}\] where \(\mathrm{supp}(X)\) is the percentage of tuples in the dataset containing the (set of) attributes \(X\) (antecedent, or LHS, of the rule). The confidence shows how frequently the dependency \(X \rightarrow Y\) is verified, knowing that the antecedent \(X\) is verified, and it is therefore an index whose value ranges between 0 and 1. A confidence equal to 1 means that only the valid and exact rules (non-relaxed FDs) will be selected, while decreasing its value implies relaxing the constraint on the number of tuples to be considered. In this context, it can be seen as an analogous metric to the g3 one, mentioned in Section~\ref{section:functional_dependencies}.
\item \textbf{Difference}: \[\mathrm{Difference}(X \rightarrow Y) = \mathrm{diff}(X, Y) = \mathrm{conf}(X, Y) - \mathrm{conf}(X \setminus X_p, Y)\] where \(X_p\) is the subset of protected attributes of the antecedent \(X\) of the dependency \(X \rightarrow Y\). The difference is basically a subtraction between the confidence value of a dependency and the confidence value calculated on the same dependency but excluding all the protected attributes from the antecedent of the rule. Being a subtraction of indices of value between 0 and 1, and given \(\mathrm{conf}(X, Y) \geq \mathrm{conf}(X \setminus X_p, Y)\), the difference is also an index whose value ranges between 0 and 1. It indicates how much a dependency is ``unethical'' (the higher the value, the more unfair is the dependency), and it gives an idea on the impact of the protected attributes on \(Y\). Last but not least, it is important to point out that the difference is a novel metric, firstly introduced in \cite{azzalini2021fair} and specifically designed with the aim of measuring the ``ethical'' level of a dependency.
\end{itemize}


\section{Statistical Concepts}
\label{section:statistical_concepts}
The aim of this section is to introduce some statistical concepts useful for fully understanding the behavior of one of the adopted tools, Ranking Facts, described later in Section~\ref{section:ranking_facts}.

The first required notion is the one of a \textbf{hypothesis test}, which in statistics is a way to test the obtained result of a survey or experiment on a sample, in order to check if the result is meaningful and extendable to the whole population or if it has happened by chance. In this context, two interpretations are proposed: the first is known as \textit{null hypothesis} (symbolized as \(H_0\)), which is the idea that there is no relationship in the population and that the relationship in the sample is caused by errors (informally, this is the ``occurred by chance'' interpretation); the second is called \textit{alternative hypothesis} (whose symbol is \(H_1\)) and it is the idea that the relationship in the sample reflects an existing relationship in the population.

Generally, the rationale behind a hypothesis test is:
\begin{itemize}
\item[1.] Assume the null hypothesis true.
\item[2.] Determine how likely the sample relationship would be if the null hypothesis were true.
\item[3.] If the sample relationship would be extremely unlikely, then \textit{reject} the null hypothesis in favour of the alternative hypothesis. If it would not be extremely unlikely, then \textit{retain} the null hypothesis.
\end{itemize}

A crucial step in hypothesis testing is to find the likelihood of the sample result if the null hypothesis were true. This probability is called \textbf{\(\bm{p}\)-value}. Low \(p\)-value means that the sample result would be unlikely if \(H_0\) were true and leads to the rejection of the null hypothesis, while high \(p\)-value means that the sample result would be likely if \(H_0\) were true and leads to the retention of the null hypothesis. To quantify how low the \(p\)-value must be in order to consider the result unlikely enough to reject the null hyphotesis, a parameter known as \textit{significance level} \(\alpha\) is used, and its value is usually set to 0.05 (5\%). The significance level represents the probability of making the mistake of rejecting the null hypothesis when in fact it is true (\textit{type I error}): if \(p\textrm{-value} > \alpha\) we accept the null hypothesis and the result is considered not statistically significant, otherwise we reject the null hypothesis and the result is said to be \textit{statistically significant}.

A particular type of hypothesis test is the \textbf{z-test}, used when data are approximately normally distributed (i.e. the plotted data have the shape of a bell curve on the graph). In order for a z-test to be used, data points should also be independent from each other and the sample size should be greater than 30. The z-test relevant to our research is the \textit{two sample z-test}, which allows to compare two proportions to check if they are the same (\(H_0\)) or not (\(H_1\)). The reference formula is: \[z = \frac{p_1 - p_2}{\sqrt{(\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2})}} = \frac{p_1 - p_2}{\sqrt{p(1 - p)(\frac{1}{n_1} + \frac{1}{n_2})}}\] where \(n_1\) and \(n_2\) are the sizes of the samples, \(p_1\) and \(p_2\) are the proportions of the samples, \(p\) is the overall sample proportion (total number of ``positive'' results over total number of people) and \(\sigma_1^2\) and \(\sigma_2^2\) represent the variances of the two populations. For the sake of completeness, we define the \textit{variance} as the measure of how far each value in the dataset is from the average value (i.e. the mean, as defined in Section~\ref{section:the_glassdoor_method}): \[\sigma^2 = \frac{\sum\limits_{i=1}^n (x_i - \mu)^2}{n}\] where \(n\) is the size of the population, \(x_i\) is the \(i\)-th value and \(\mu\) represents the mean. In the z-score formula above, for the sake of simplicity, \(\sigma_1^2\) and \(\sigma_2^2\) are approximated by the variance of the Bernoulli distribution (i.e. the probability distribution for a random experiment with only two possible outcomes). To better clarify, we will now consider the example of testing two different COVID-19 vaccines: the first works on 248 people out of a sample of 496, while the second works on 23 people in a sample of 100. To check if the vaccines are comparable we firstly calculate the proportions: \[p_1 = 248 / 496 = 0.5\] \[p_2 = 23 / 100 = 0.23\]
The overall sample proportion is: \[p = \frac{248 + 23}{496 + 100} \simeq 0.45\]
And finally the z-score is: \[z \simeq \frac{0.5 - 0.23}{\sqrt{0.45(1 - 0.45)(\frac{1}{496} + \frac{1}{100})}} \simeq 4.95\]
To find out if the obtained result should lead us to accept or reject the null hypothesis, we can look at the known values of z-score, related to the most commonly used \(\alpha\) values. For example, the z-score related to \(\alpha = 0.05\) is 1.96, meaning that 95\% of the area under the normal curve lies within the range \([-1.96, +1,96]\), and since \(4.95 > 1.96\) we can reject the null hypothesis (for z-scores higher than 1.96 with \(\alpha = 0.05\), \(p\textrm{-value} < 0.05\)).


\section{The ``Glassdoor Method''}
\label{section:the_glassdoor_method}
After having described the basics, we will now make an overview of the tools used for this research. The first one is a technical guide to analyze gender pay gap in a company, provided by \textbf{Glassdoor} in \cite{chamberlain2017analyze}.

Glassdoor is a website in which employees and ex-employees of companies anonimously review enterprises and their superiors, with the overall aim of providing insights about jobs and companies and helping people find the most suitable working position for them. The society was founded in 2007 in the U.S. and the website was made available in 2008; since then, the company has grown to become the worldwide leader in the sector.

As specified in the introduction of the guide \cite[p.~2]{chamberlain2017analyze}, according to a 2016 Glassdoor survey, 67\% of the U.S. employees would not apply for jobs at employers where they believe a gender pay gap exists. The purpose of the report is therefore to help HR practitioners in analyzing the internal gender pay gap of their companies, by providing them specific technical knowledge.

First of all, by ``gender pay gap'' the author means:
\begin{quote}\emph{The difference between average pay for men and women, both before and after we've accounted for differences among workers in education, experience, job roles, employee performance and other factors aside from gender that affect pay.} \cite[p.~3]{chamberlain2017analyze}\end{quote}
Two measures are proposed in the report, respectively referred as ``unadjusted'' and ``adjusted'' pay gap:
\begin{itemize}
\item \textbf{``Unadjusted'' pay gap}:
\begin{quote}\emph{Average pay for men as a group, compared to average pay for women as a group.} \cite[p.~3]{chamberlain2017analyze}\end{quote}
Therefore, the formula for estimating ``unadjusted'' gender pay gap is: \[U = \frac{\mathrm{avg}(BasePay)_m - \mathrm{avg}(BasePay)_f}{\mathrm{avg}(BasePay)_m}\] where \(\mathrm{avg}(BasePay)_m\) is the average pay (arithmetic mean of salaries) of male employees, while \(\mathrm{avg}(BasePay)_f\) is the average pay of female employees.
For the sake of completeness, despite being a basic mathematical concept, we define the \textit{mean} as the sum of a collections of numbers (in this case, salaries) divided by the count of numbers in the collection (the total amount of males or females). Taking \(n\) as total number of male employees: \[\mathrm{avg}(BasePay)_m = \frac{\sum\limits_{i=1}^n BasePay_i}{n}\] and the same holds for female employees.
\item \textbf{``Adjusted'' pay gap}: while the ``unadjusted'' pay gap is basically a simple comparison of all women with all men, the ``adjusted'' pay gap compare similarly situated male and female employees, in order to include in the calculation the numerous factors that affect the pay (e.g. job title, or educational level). The estimation of the ``adjusted'' pay gap is based on linear regression, a concept presented in Section~\ref{section:linear_regression}, and the reference formula is: \[y_i = \beta_1\textit{Male}_i + \beta_2X_i + \epsilon_i\] where \(y_i\) is the annual salary of worker \(i\), \(\textit{Male}_i\) is a dummy indicator equal to 1 for males and 0 for females, and \(X_i\) is a collection of attributes of employees which may be relevant for the calculation (job title, educational level, etc.). The estimated coefficient \(\beta_1\) represents the approximate pay advantage for men compared to women.
\end{itemize}


\section{FAIR-DB}
\label{section:fair-db}
The second tool adopted for this research is called \textbf{FAIR-DB} (\textit{\textbf{F}unction\textbf{A}l Dependenc\textbf{I}es to discove\textbf{R} \textbf{D}ata \textbf{B}ias}), and it is a framework with the aim of discovering unfair behaviors in datasets, developed at Politecnico di Milano. As the name itself suggests, FAIR-DB is based on functional dependencies, and it falls within the category of preprocessing techniques since it works by finding conditions (constraints) already present in the data. The developers documented the functioning of FAIR-DB in \cite{azzalini2021fair}, by providing an overview of the tool, together with a clarifying example.

\begin{figure}[t!]
\includegraphics[scale=.65]{figures/fair-db_framework.pdf}
\centering
\caption{Steps of the FAIR-DB framework. Image based on the one shown in \cite{azzalini2021fair}.}
\label{fig:fair-db_framework}
\end{figure}

Figure~\ref{fig:fair-db_framework} shows the framework workflow, while a brief explanation of each phase, as documented in \cite{azzalini2021fair}, is reported below.
\begin{itemize}
\item \textbf{Data preparation and exploration}: data are imported and data integration is eventually performed. Data cleaning, feature selection and discretization techniques are also applied in this phase, in order to deal with missing values, select the smallest set of attributes relevant for the analysis and transform data from numerical to nominal data type. Data are finally plotted in order to help the user in identifying groups in the dataset and eventually majority and minority classes.
\item \textbf{ACFD Discovery and filtering}: the \textit{ACFD Discovery} algorithm, presented in \cite{rammelaere2018revisiting}, is applied to extract approximate conditional functional dependencies from the dataset. The algorithm takes as input the dataset and three threshold parameters: \textit{minimum support}, \textit{minimum confidence} and \textit{maximum antecedent size} of the ACFD sought. From the output, dependencies not involving at least one of the protected attributes and the target attribute (the one used as reference to search for discrimination, e.g. \(\mathit{Income}\)) are removed, as well as dependencies containing variables (in which one or more attributes are not assigned to a specific value, e.g. the attribute \(\mathit{Ideal}\) in \(\mathit{Temperature} = \mlq 28 \mrq, \mathit{pH} = \mlq 7 \mrq \rightarrow \mathit{Ideal}\)).
\item \textbf{ACFD selection}: for each ACFD, some metrics are computed to capture the ``ethical level'' of the dependency. In particular, the \textit{difference} metric described in Section~\ref{section:evaluation_metrics}, as mentioned in the section, is a novel score introduced for this purpose, and a second measure called \textit{p-Difference} is calculated for each protected attribute. The p-Difference indicates how much a dependency shows bias with respect to a specific protected attribute, and it is computed in the same way as the difference, but excluding the attribute from the antecedent of the rule. According to the values of the metrics, the most interesting ACFDs are selected.
\item \textbf{ACFD ranking}: the ACFDs are ranked in descending order of importance according to \textit{support}, \textit{difference}, or \textit{mean}. The support emphasize the \textit{pervasiveness} of a rule, because it indicates the number of tuples involved by the dependency, so the higher the value, the more tuples are affected by the ACFD. The difference privileges the \textit{unethical aspect} of a rule, because it highlights dependencies where the values of the protected attributes influence most their RHS. The mean is computed as mean of support and difference, and therefore it gives more importance to the rules with the \textit{best trade-off} between pervasiveness and unethical perspective.
\item \textbf{ACFD user selection and scoring}: the user selects \(N\) ACFDs perceived as the most problematic, and the system computes metrics (based on support, difference, and p-Difference of the selected rules) to summarize the level of unfairness of the dataset.
\end{itemize}


\section{Ranking Facts}
\label{section:ranking_facts}
The third tool used for this research is called \textbf{Ranking Facts}, a Web-based application (there also exists a notebook version) developed by the team of \textit{Data, Responsibly}\footnote{Available at: \url{http://demo. dataresponsibly.com/rankingfacts/.}}. Ranking Facts, as the name itself suggests, is a \textit{ranking} tool: ranking is an action commonly performed by the vast majority of the algorithms we use every day: Google itself ranks the results of our searches and provides us with a list in descending order of relevance, and the same mechanism is used in various contexts of different nature, like dating or hiring applications. These specific scenarios are particularly relevant, because it is people who are ranked, and therefore discrimination against individuals or protected groups could arise, or the outcome could exhibit low diversity. Ranking Facts is based on the concept of \textit{nutritional labels}, in analogy to the food industry, where simple, standard labels convey information about the ingredients and production processes. Similarly, in the tool nutritional labels are derived as part of the complex process that gave rise to the data or model they describe, embodying the paradigm of interpretability-by-design.

As documented in \cite{yang2018nutritional}, Ranking Facts is a collection of visual widgets with the aim of providing to the user information about the ranking in terms of stability, fairness and diversity. A brief description of how they work, taken from \cite{yang2018nutritional}, is reported below.
\begin{itemize}
\item \textbf{Recipe} and \textbf{Ingredients}: the former widget succintly describes the ranking algorithm, by listing the attributes used for ranking together with their weights, as specified by the user; while the latter shows, in descending order of importance, the attributes that really affect the ranking.
\item \textbf{Stability}: it explains whether the ranking methodology is robust on the specific dataset in use. An unstable ranking is one where slight changes to the data (e.g. due to uncertainty and noise), or to the methodology (e.g. by slightly adjusting the weights of the attributes in the recipe) could lead to a significant change in the output.
\item \textbf{Fairness}: it quantifies whether the ranked output exhibits statistical parity (group fairness) with respect to one or more protected attributes, such as gender or race of individuals. The notion of fairness is defined specifically for rankings and it can be computed comparing only binary categorical attributes (i.e. non-numerical attributes with just two possible values). The summary view of the widget presents the output of three fairness measures:

\begin{itemize}
\item \textbf{FA*IR} \cite{zehlike2017fa*ir}: ranking algorithm based on the assumption that on a ranking, the desired good for an individual is to appear in the result and to be ranked among the top-\(k\) positions. The outcome is therefore unfair if members of a protected group are systematically ranked lower than those of a privileged group, and a ranking algorithm discriminates unfairly if this ranking decision is based fully or partially on a protected feature.

The \textit{ranked group fairness} criterion used by the algorithm compares the number of protected elements in every prefix of the ranking (i.e. the top-\(i\) positions of the ranking, with \(i \in [1, k]\)) with the expected number of protected elements if they were picked at random using Bernoulli trials (independent ``coin tosses'') with success probability \(p\). The statistical test also includes a significance parameter \(\alpha\), corresponding to the probability of a type I error, which means rejecting a fair ranking. A clarifying example is provided in Table~\ref{table:fa*ir_example}.

\begin{table}
\begin{tabular}{|p{.85cm}|p{.5cm}p{.5cm}p{.5cm}p{.5cm}p{.5cm}p{.5cm}p{.5cm}p{.5cm}p{.5cm}p{.5cm}p{.5cm}p{.5cm}|}
\hline
\diagbox{\(p\)}{\(k\)} & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12\\
\hline
0.1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
0.2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 1\\
0.3 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 1 & 1 & 1 & 2\\
0.4 & 0 & 0 & 0 & 0 & 1 & 1 & 1 & 1 & 2 & 2 & 2 & 3\\
0.5 & 0 & 0 & 0 & 1 & 1 & 1 & 2 & 2 & 3 & 3 & 3 & 4\\
0.6 & 0 & 0 & 1 & 1 & 2 & 2 & 3 & 3 & 4 & 4 & 5 & 5\\
0.7 & 0 & 1 & 1 & 2 & 2 & 3 & 3 & 4 & 5 & 5 & 6 & 6\\
\hline
\end{tabular}
\centering
\caption{Minimum number of candidates in the protected group that must appear in the top-\(k\) positions to pass the ranked group fairness criterion with \(\alpha = 0.1\). Considering for example \(\mathit{gender}\) as a protected attribute with values \(\mlq M \mrq\) and \(\mlq F \mrq\), the minimum number of females (or eventually males) appearing in the top-5 with \(p=0.4\) is \(1\). Table based on the one shown in \cite{zehlike2017fa*ir}.}
\label{table:fa*ir_example}
\end{table}

The algorithm produces a top-\(k\) ranking that satisfies the ranking group fairness criterion mentioned above while maximizing \textit{utility}, which means selecting the ``best'' tuples, assigning them a score based on the relevant attributes used for the evaluation (e.g. picking the most qualified candidates for a job position by looking at their educational level).

\item \textbf{Proportion} \cite{vzliobaite2017measuring}: this measure is based on the concept of z-test, as described in Section~\ref{section:statistical_concepts}.

\item \textbf{Pairwise}: also known as \textit{pairwise comparison}, it is a tool for prioritizing and ranking multiple options relative to each other. A matrix is generally used to compare each option in pairs and determine which is the preferred choice or has the highest level of importance based on defined criteria. At the end of the comparison process, each option has a rank or relative rating as compared to the rest of the options. Table~\ref{table:pairwise_comparison_example} provides an example: scores are assigned based on how strongly the consumption of a drink on the left dominates that of a drink at the top. For example, when coffee on the left is compared with wine at the top, since coffee appears to be extremely more consumed, 9 is entered in the first row and second column position. A score of $\frac{1}{9}$ is automatically entered in the second row and first column position. According to the matrix, the final ranking would be:\\\(\mathit{Sodas}:~0.252\), \(\mathit{Water}:~0.228\), \(\mathit{Beer}:~0.164\), \(\mathit{Milk}:~0.148\), \(\mathit{Coffee}:~0.142\), \(\mathit{Tea}:~0.046\), \(\mathit{Wine}:~0.019\).

\begin{table}
\begin{tabular}{|p{1cm}|p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}|}
\hline
& Coffee & Wine & Tea & Beer & Sodas & Milk & Water\\
\hline
Coffee & 1 & 9 & 3 & 1 & $\frac{1}{2}$ & 1 & $\frac{1}{2}$\\
Wine & $\frac{1}{9}$ & 1 & $\frac{1}{3}$ & $\frac{1}{9}$ & $\frac{1}{9}$ & $\frac{1}{9}$ & $\frac{1}{9}$\\
Tea & $\frac{1}{3}$ & 3 & 1 & $\frac{1}{4}$ & $\frac{1}{5}$ & $\frac{1}{4}$ & $\frac{1}{5}$\\
Beer & 1 & 9 & 4 & 1 & $\frac{1}{2}$ & 1 & 1\\
Sodas & 2 & 9 & 5 & 2 & 1 & 2 & 1\\
Milk & 1 & 9 & 4 & 1 & $\frac{1}{2}$ & 1 & $\frac{1}{2}$\\
Water & 2 & 9 & 5 & 1 & 1 & 2 & 1\\
\hline
\end{tabular}
\centering
\caption{Drink consumption in the U.S. represented in a pairwise comparison matrix. Table based on the one shown in \cite{saaty2003magic}.}
\label{table:pairwise_comparison_example}
\end{table}
\end{itemize}

All these measures are statistical tests, and whether a result is fair is determined by the computed \(p\)-value.
\item \textbf{Diversity}: since fairness is also related to representation, this widget shows diversity with respect to a set of demographic categories of individuals, or a set of categorical attributes of other kinds of items, by displaying the proportion of each category in the top-10 ranked list and overall (i.e. considering all the elements in the ranking).
\end{itemize}
